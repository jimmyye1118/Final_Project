import sounddevice as sd
import numpy as np
import whisper
import tempfile
import wave
import pyttsx3
from sentence_transformers import SentenceTransformer, util
import threading
# import keyboard  # éœ€è¦å®‰è£ï¼špip install keyboard

# åˆå§‹åŒ–æ¨¡å‹
whisper_model = whisper.load_model("base")
embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
tts_engine = pyttsx3.init()

# é—œéµå­—èˆ‡å‹•ä½œ
keyword_actions = {
    "é–‹å§‹": lambda: print("é–‹å§‹ä»»å‹™"),
    "æš«åœ": lambda: print("æš«åœ"),
    "ç´…è‰²": lambda: print("ç´…è‰²"),
    "è—è‰²": lambda: print("è—è‰²"),
    "é»ƒè‰²": lambda: print("é»ƒè‰²"),
    "ç¶ è‰²": lambda: print("ç¶ è‰²"),
}

# é å…ˆå»ºç«‹èªæ„å‘é‡
keyword_list = list(keyword_actions.keys())
keyword_embeddings = embedding_model.encode(keyword_list, convert_to_tensor=True)

recording_data = []
is_recording = False
fs = 16000  # å–æ¨£ç‡

def audio_callback(indata, frames, time, status):
    if is_recording:
        recording_data.append(indata.copy())

def record_audio():
    global recording_data
    recording_data = []
    print("é–‹å§‹éŒ„éŸ³...")
    with sd.InputStream(samplerate=fs, channels=1, dtype='int16', callback=audio_callback):
        while is_recording:
            sd.sleep(100)
    print("éŒ„éŸ³çµæŸ")

def speak(text):
    print(f"TTS èªªè©±ï¼š{text}")
    tts_engine.say(text)
    tts_engine.runAndWait()

def save_audio_to_file():
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        with wave.open(f.name, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(fs)
            audio_data = np.concatenate(recording_data, axis=0)
            wf.writeframes(audio_data.tobytes())
        return f.name

def process_command(audio_path):
    result = whisper_model.transcribe(audio_path, language="zh")
    text = result['text'].strip()
    print(f"è¾¨è­˜çµæœï¼š{text}")

    user_embedding = embedding_model.encode(text, convert_to_tensor=True)
    cosine_scores = util.cos_sim(user_embedding, keyword_embeddings)
    best_idx = cosine_scores.argmax()
    best_score = cosine_scores[0][best_idx].item()
    best_keyword = keyword_list[best_idx]

    print(f"ğŸ” æœ€ç›¸ä¼¼ï¼š{best_keyword}ï¼ˆåˆ†æ•¸ï¼š{best_score:.2f}ï¼‰")

    if best_score >= 0.6:
        keyword_actions[best_keyword]()
    else:
        speak("è«‹å†èªªä¸€æ¬¡")

def main_loop():
    global is_recording
    print("æŒ‰ä¸‹ g é–‹å§‹éŒ„éŸ³ï¼Œs åœæ­¢éŒ„éŸ³ä¸¦è¾¨è­˜ï¼Œq é›¢é–‹ï¼š")
    while True:
        key = input()

        if key == "g" and not is_recording:
            is_recording = True
            threading.Thread(target=record_audio).start()

        elif key == "s" and is_recording:
            is_recording = False
            audio_file = save_audio_to_file()
            process_command(audio_file)

        elif key == "q":
            print("å·²é€€å‡ºç¨‹å¼")
            break

        else:
            print("ç„¡æ•ˆæŒ‡ä»¤ï¼Œè«‹é‡æ–°è¼¸å…¥")

main_loop()